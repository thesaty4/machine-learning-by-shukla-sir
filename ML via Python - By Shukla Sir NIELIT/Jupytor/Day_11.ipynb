{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['GRE Score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "#Chance of admit is not dependent on serial number, therefore we do not need serial number\n",
    "#for ML purpose\n",
    "\n",
    "df.drop(['Serial No.'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research  \\\n",
       "0        337          118                  4  4.5  4.5  9.65         1   \n",
       "1        324          107                  4  4.0  4.5  8.87         1   \n",
       "2        316          104                  3  3.0  3.5  8.00         1   \n",
       "3        322          110                  3  3.5  2.5  8.67         1   \n",
       "4        314          103                  2  2.0  3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit  \n",
       "0             0.92  \n",
       "1             0.76  \n",
       "2             0.72  \n",
       "3             0.80  \n",
       "4             0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Chance of Admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Chance of Admit '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Chance of Admit ': 'Chance of Admit'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8)\n",
      "(400, 7)\n"
     ]
    }
   ],
   "source": [
    "#X is feature on which outcome y is dependent\n",
    "print(df.shape)\n",
    "X=df.drop(['Chance of Admit'],axis=1)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.92\n",
      "1      0.76\n",
      "2      0.72\n",
      "3      0.80\n",
      "4      0.65\n",
      "       ... \n",
      "395    0.82\n",
      "396    0.84\n",
      "397    0.91\n",
      "398    0.67\n",
      "399    0.95\n",
      "Name: Chance of Admit, Length: 400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#y is outcome which we want to predict through Machine Learning\n",
    "y=df['Chance of Admit']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now X (Features) and y (Outcome) is ready\n",
    "#Now split the data into two parts: train data(320 rows) and test data(80 rows)\n",
    "#Generally testing data is kept as 20%(0.20) to 30%(0.30)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR', 'CGPA',\n",
       "       'Research'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only these three lines in python will create a Machine Learning\n",
    "#Model for you\n",
    "from sklearn.linear_model import LinearRegression\n",
    "m=LinearRegression()\n",
    "m.fit(X_train,y_train)\n",
    "\n",
    "#m object is a ML Model, which can predict outcome, if feature is given\n",
    "# as input to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test is actual outcome directly taken from sample data\n",
    "#y_predict is predicted outcome by the ML model i.e. m in this case\n",
    "df1=pd.DataFrame({\"Actual\": y_test,\"Predicted\":y_predict })\n",
    "df1.to_csv(\"04_Sep_Output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test is actual outcome directly taken from sample data\n",
    "#y_predict is predicted outcome by the ML model i.e. m in this case\n",
    "df1=pd.DataFrame({\"Actual\": y_test,\"Predicted\":y_predict })\n",
    "df1['error']=df1['Actual']-df1['Predicted']\n",
    "df1['error']=df1['error'].abs()\n",
    "df1.to_csv(\"04_Sep_Output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.774720</td>\n",
       "      <td>0.014720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.771065</td>\n",
       "      <td>0.081065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.660681</td>\n",
       "      <td>0.049319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.014679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.617680</td>\n",
       "      <td>0.112320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted     error\n",
       "222    0.76   0.774720  0.014720\n",
       "111    0.69   0.771065  0.081065\n",
       "379    0.71   0.660681  0.049319\n",
       "108    0.93   0.915321  0.014679\n",
       "196    0.73   0.617680  0.112320"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04818434537326606\n"
     ]
    }
   ],
   "source": [
    "Mean_Absolute_Error=df1['error'].mean()\n",
    "print(Mean_Absolute_Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.8% is the error of your ML model created using Linear Regression\n",
    "#Algorithm\n",
    "#why Error is modified when data is same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048184345373266046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_test,y_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your GRE Score (between 290 to 340):310\n",
      "What is your TOEFL Score (between 90 to 120):110\n",
      "What is your University Rating ( 1 to 5 ):4\n",
      "Rate your Statement of Purpose ( 1 to 5):3\n",
      "What is strength of  your Letter of Recommendation ( 1 to 5) :4\n",
      "What is your CGPA ( 6 to 10):8.07\n",
      "Do You have Research Experience (Enter 0 for No and 1 for Yes:1\n",
      "Your Chance of admission is: 63.11224396566375   to   72.73224396566376  Percent\n"
     ]
    }
   ],
   "source": [
    "#data of a new user or current user who wants to predict the outcome(chance of his admission)\n",
    "#Deployment of a Machine Learning model\n",
    "gre=int(input(\"What is your GRE Score (between 290 to 340):\"))\n",
    "toefl=int(input(\"What is your TOEFL Score (between 90 to 120):\"))\n",
    "univ=int(input(\"What is your University Rating ( 1 to 5 ):\"))\n",
    "sop=float(input(\"Rate your Statement of Purpose ( 1 to 5):\"))\n",
    "lor=float(input(\"What is strength of  your Letter of Recommendation ( 1 to 5) :\"))\n",
    "cgpa=float(input(\"What is your CGPA ( 6 to 10):\"))\n",
    "research=int(input(\"Do You have Research Experience (Enter 0 for No and 1 for Yes:\"))\n",
    "\n",
    "#Very important: the sequence of new data will be exactly same as per training data columns i.e.\n",
    "#X_train columns\n",
    "list=[gre,toefl,univ,sop,lor,cgpa,research]\n",
    "\n",
    "#predict function takes input argument i.e. feature data as Data Frame which may consist\n",
    "#of many rows or records or entity data\n",
    "\n",
    "Newdf=pd.DataFrame([list])\n",
    "y_p=m.predict(Newdf)\n",
    "\n",
    "print(\"Your Chance of admission is:\",y_p[0]*100-4.81,\"  to  \",y_p[0]*100+4.81,\" Percent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=m.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04459219397029629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_train,y_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished entire process of machine learning for this particular problem in\n",
    "#a simple way\n",
    "\n",
    "#How can you say that this algorithm is better\n",
    "#only by experiments\n",
    "#you make a model using all possible algorithms and test that, find error\n",
    "#whatever has minimum error, that algo is suitable for your problem.\n",
    "#Apply algorithm depending on type of problem eg. regression in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,y_train)\n",
    "#rfr is the model on basis of this algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_predict=rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05259999999999996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_test,yr_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algorithm Name: Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train,y_train)\n",
    "#dtr is a ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydtr_predict=dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_test,ydtr_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have applied three regression algorithms\n",
    "#We found that error is lowest in case of Linear Regression Algorithm\n",
    "#that means m is best model for my problem\n",
    "#therefore final decision is that I will depoly m as my ML Model\n",
    "#for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many algorithms are there\n",
    "#No one knows why? bcoz research is going on......\n",
    "#what you know is that it is a regression problem\n",
    "#So I have to apply regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algoirthm Name: Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "s = SVR()\n",
    "s.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06646593170997861\n"
     ]
    }
   ],
   "source": [
    "ys_predict=s.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_test,ys_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algorithm: Bayesian Ridge Regression is little better than linear regression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047889006052331144\n"
     ]
    }
   ],
   "source": [
    "ys_predict=br.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "e=mean_absolute_error(y_test,ys_predict)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
